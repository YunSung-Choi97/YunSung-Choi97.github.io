---
title: "[영상신호처리] 08. 과제 2 (Disparity map by Stereo Vision)"
layout: article
aside: false
sidebar: false
categories: [KyungHee Univ., C++, Digital Image Processing]
license: false
show_subscribe: false
show_title: true
mathjax : true
---

문제 해결을 위해 작성된 Main함수(Button을 Click하여 동작하는 함수)를 제외한 기능을 위해 작성된 나머지 함수에 대해서는 가장 하단에 따로 첨부해두었습니다.<br>

```cpp
void Stereo_Image(BYTE** Left_Image, BYTE** Right_Image, BYTE** Result, int width, int height, int d_max, int window_size);
int Compute_distance(BYTE** Left_Image, BYTE** Right_Image, int x0, int y0, int width, int height, int d_max, int window_size);
void INormalize2D(int** Distance, BYTE** Result, int width, int height);
void DisplayProcessingTime_2(clock_t start1, clock_t end1, clock_t start2, clock_t end2);
```

## Stereo vision을 이용해 disparity map 구하기

### 좌/우 영상으로 Disparity map 구하기 (main)

```cpp
void CHomework::OnClickedStereo()
{
	// 각각 읽어올 영상의 원점좌표 정보, 가로길이 정보, 세로길이 정보를 저장할 변수
	int x0, y0, w, h;
	// 읽어올 영상 중 각각 Left영상, Right영상 정보와 출력할 영상 정보를 저장할 BYTE 정보
	BYTE** Limg, ** Rimg, ** Result;
	// 7x7, 21x21 window를 이용해 disparity map의 processing time을 구하기 위한 시간 정보를 저장할 변수
	clock_t start_time7x7, end_time7x7, start_time21x21, end_time21x21;

	// 1) 파일을 읽어와 (0, 40)위치에 display
	// 2) 읽어온 파일의 가로, 세로, 원점좌표 정보를 저장
	// 3) Left Image 초기화
	// 4) 초기화된 Left Image cmatrix에 회색조 영상 정보 저장
	Display_BMP_File("c:\\Limg1.bmp", 0, 40);
	GetCurrentImageInfo(&w, &h, &x0, &y0);
	Limg = cmatrix(h, w);
	GetCurrentImageGray(Limg);

	// 1) 파일을 읽어와 (w, 40)위치에 display
	// 2) 읽어온 파일의 가로, 세로, 원점좌표 정보를 저장
	// 3) Right Image 초기화
	// 4) 초기화된 Right Image cmatrix에 회색조 영상 정보 저장
	Display_BMP_File("c:\\Rimg1.bmp", w, 40);
	GetCurrentImageInfo(&w, &h, &x0, &y0);
	Rimg = cmatrix(h, w);
	GetCurrentImageGray(Rimg);

	// 결과값을 저장할 Result 초기화
	Result = cmatrix(h, w);

	// 1) Limg와 Rimg를 Stereo_Image함수를 이용해 Search Range = 30, window size = 7로 Result 계산
	// 2) 화면에 출력
	// + processing time을 구하기 위해 Stereo_Image함수 앞뒤로 clock()을 넣어줌.
	start_time7x7 = clock();
	Stereo_Image(Limg, Rimg, Result, w, h, 30, 7);
	end_time7x7 = clock();
	DisplayCimage2D(Result, w, h, x0 - w, y0 + h, true);

	// 1) Limg와 Rimg를 Stereo_Image함수를 이용해 Search Range = 30, window size = 21로 Result 계산
	// 2) 화면에 출력
	// + processing time을 구하기 위해 Stereo_Image함수 앞뒤로 clock()을 넣어줌.
	start_time21x21 = clock();
	Stereo_Image(Limg, Rimg, Result, w, h, 30, 21);
	end_time21x21 = clock();
	DisplayCimage2D(Result, w, h, x0, y0 + h, true);

	// 7x7, 21x21 window를 사용했을 때의 processing time을 각각 화면에 출력
	DisplayProcessingTime_2(start_time7x7, end_time7x7, start_time21x21, end_time21x21);

	// 할당된 matrix 해제
	free_cmatrix(Limg, h, w);
	free_cmatrix(Rimg, h, w);
	free_cmatrix(Result, h, w);
}
```

<br>

### Functions.

```cpp
// 1) Right Image의 모든 점에 대하여, 점을 중심으로 형성된 window와 가장 비슷한 Left Image 부분을 찾아 위치차이를 알아냄
// 2) 위치차이를 영상정보로 사용할 수 있도록 BYTE으로 normalize
void Stereo_Image(BYTE** Left_Image, BYTE** Right_Image, BYTE** Result, int width, int height, int d_max, int window_size)
{
	int** Distance;
	Distance = imatrix(height, width);

	for (int y = 0; y < height; y++)
		for (int x = 0; x < width; x++)
			Distance[y][x] = Compute_distance(Left_Image, Right_Image, x, y, width, height, d_max, window_size);

	INormalize2D(Distance, Result, width, height);
	free_imatrix(Distance, height, width);
}
```

```cpp
// Right Image의 한 점에 대하여, 점을 중심으로 형성된 window와 가장 비슷한 Left Image 부분을 찾아 위치차이 계산하는 함수
int Compute_distance(BYTE** Left_Image, BYTE** Right_Image, int x0, int y0, int width, int height, int d_max, int window_size)
{
	int min_D, min_dx, half_ws;
	min_D = 9999;
	min_dx = 0;
	half_ws = window_size / 2;
	
	if (half_ws <= x0 && x0 < width - half_ws - d_max && half_ws <= y0 && y0 < height - half_ws)
	{
		for (int dx = 0; dx < d_max; dx++)
		{
			int sum_gaps = 0;

			for (int y = y0 - half_ws; y <= y0 + half_ws; y++)
				for (int x = x0 - half_ws; x <= x0 + half_ws; x++)
					sum_gaps += abs(Right_Image[y][x] - Left_Image[y][x + dx]);
			
			if (sum_gaps < min_D)
			{
				min_D = sum_gaps;
				min_dx = dx;
			}
		}
		return min_dx;
	}
	else
		return 0;
}
```

```cpp
// 위치차이를 영상정보로 사용할 수 있도록 BYTE으로 normalize하는 함수
void INormalize2D(int** Distance, BYTE** Result, int width, int height)
{
	int max = -9999, min = 9999;
	int value;

	for (int y = 0; y < height; y++)
	{
		for (int x = 0; x < width; x++)
		{
			value = Distance[y][x];
			if (value > max)
				max = value;
			if (value < min)
				min = value;
		}
	}

	if (max == min)
	{
		for (int y = 0; y < height; y++)
			for (int x = 0; x < width; x++)
				Result[y][x] = 0;
		return;
	}

	double dfactor = 255 / (max - min);
	for (int y = 0; y < height; y++)
		for (int x = 0; x < width; x++)
			Result[y][x] = (BYTE)((Distance[y][x] - min) * dfactor);
}
```

```cpp
// 처리시간을 계산하여 화면에 출력
void DisplayProcessingTime_2(clock_t start1, clock_t end1, clock_t start2, clock_t end2)
{
	// 시간차를 저장할 변수
	double time_dif1, time_dif2;

	// 클럭정보로부터 시간차를 계산해 처리시간을 화면에 출력
	time_dif1 = (double)((end1 - start1) / (double)CLOCKS_PER_SEC);
	time_dif2 = (double)((end2 - start2) / (double)CLOCKS_PER_SEC);
	CString ViewMsg;
	ViewMsg.Format(_T("Processing time (7x7 window: %6.3f sec) and (21x21 window: %6.3f sec)"), time_dif1, time_dif2);
	SetViewMsg(ViewMsg);
}
```

<br>

## 결과

### Limg1.bmp와 Rimg1.bmp

![1-1](https://user-images.githubusercontent.com/79047370/114783331-e82efe00-9db4-11eb-80f3-77fcb551302e.png)
사진의 왼쪽 상단 영상이 Left-Image이고, 오른쪽 상단 영상이 Right-Image이다.<br>
사진의 왼쪽 하단 영상이 7x7 window를 통해 얻어낸 disparity map이고, 오른쪽 하단 영상이 21x21 window를 통해 얻어낸 disparity map이다.<br>

<br>

### Limg2.bmp와 Rimg2.bmp

![2-1](https://user-images.githubusercontent.com/79047370/114783387-eb29ee80-9db4-11eb-85fb-4131606167cf.png)
사진의 왼쪽 상단 영상이 Left-Image이고, 오른쪽 상단 영상이 Right-Image이다.<br>
사진의 왼쪽 하단 영상이 7x7 window를 통해 얻어낸 disparity map이고, 오른쪽 하단 영상이 21x21 window를 통해 얻어낸 disparity map이다.<br>

<br>

영상에서 밝게 나타난 부분들이 값이 크다는 것을 의미하고, 이는 픽셀에 대해 왼쪽 영상과 오른쪽 영상 간에 거리값이 크다는 것을 의마한다. 즉, 피사체가 가까이 있음을 의미하게 된다. 반대로 어둡게 나타난 부분들이 멀리 있는 사물들을 나타낸다. 따라서, 첫번째 결과사진에서 스탠드 조명이 가장 밝은 모습을 띄기 때문에 가장 카메라와 가까이 있고, 얼굴형태의 석고 조각이 다음으로 밝게 보이기 때문에 다음으로 가까이 있는 것으로 파악할 수 있다. 배경으로 보이는 책장은 상대적으로 멀기 때문에 거리차이가 거의 없고 굉장히 어둡게 나타나는 것을 확인할 수 있다. 또한 두번째 결과사진에서 어두운 색의 무늬가 있는 부분이 disparity map에서 굉장히 밝게 나타난 것으로 보아 다른 부분보다 앞으로 나와있는 구조인 것을 알 수 있다.

<br>

위 결과들을 보면 window size가 작은수록 작은 범위마다 값이 변하는 모습을 보이고 다양한 값(색)을 갖고 있는 모습을 보이지만, 매끄럽지 못하고 노이즈가 분포하는 것과 같은 형태로 영상이 나타나고 있다. 반대로 window size가 커지게 되면 세밀하지 않고 거리가 비슷해 보이는 사물 간에는 구분이 되지 않는 모습을 볼 수 있다. 하지만 조금 더 매끄럽고 노이즈가 줄어든 것과 같은 형태의 영상을 얻을 수 있었다.<br>
이와 같은 방식을 SAD 방식이라고 한다. SAD 방식을 이용해 결과를 얻는 방식은 window size를 선택하는 것이 쉽지 않다.