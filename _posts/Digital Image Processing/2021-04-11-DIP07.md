---
title: "[영상신호처리] 07. 과제 1 (Filters)"
layout: article
aside: false
sidebar: false
categories: [KyungHee Univ., C++, Digital Image Processing]
license: false
show_subscribe: false
show_title: true
mathjax : true
---

문제 해결을 위해 작성된 Main함수(Button을 Click하여 동작하는 함수)를 제외한 기능을 위해 작성된 나머지 함수에 대해서는 가장 하단에 따로 첨부해두었습니다.<br>

```cpp
// Real파트와 Imag파트를 이용해 스펙트럼을 구해주는 함수 (log scale을 이용 O/X)
void Compute_Spectrum(double **Real, double **Imag, int width, int height, double **Spectrum);
void Compute_Spectrum_log(double **Real, double **Imag, int width, int height, double **Spectrum);
// 스펙트럼을 영상신호로 사용하기 위해 BYTE타입으로 정규화시키는 함수
void DNormalize2D(double **p1, BYTE **p2, int W, int H);
// 영상신호를 중심이동을 해주는 함수
void TranslationCenter(BYTE **image, int width, int height);
// FFT 계산을 위해 영상신호를 Real파트와 Imag파트로 나눠주는 함수
void Image_to_RealandImag(BYTE **image, double **Real, double **Imag, int width, int height);
// clock을 입력받아 Processing Time을 계산하고 출력해주는 함수
void DisplayProcessingTime(clock_t start_time, clock_t end_time);
// 스펙트럼을 구성하는 특정 주파수대역의 값을 제거해주는 함수
void BandRejectFilter(double **Real, double **Imag, int width, int height, int distance, int range);
// 스펙트럼을 구성하는 특정 부분의 값을 제거해주는 함수
void Filter2(double **Real, double **Imag, int noise_x, int noise_y);
// 영상의 임의의 점에 대하여 근처 값들의 평균값으로 값을 대체해주는 함수
void MeanFilter(BYTE **image, int width, int height, int window_size);
// 영상의 임의의 점에 대하여 근처 값들의 중간값으로 값을 대체해주는 함수
void MedianFilter(BYTE **image, int width, int height, int window_size);
// MedianFilter를 위해 선택정렬 방식으로 sort시켜주는 함수
void selectionsort(BYTE *values, int length);

typedef struct tagCOMPLEX {
    double real, imag;
} COMPLEX;
// FFT/IFFT 계산해주는 함수 & FFT/IFFT 구현
void FFT_2D(double **Real1, double **Imag1, double **Real2, double **Imag2, int width, int height);
void IFFT_2D(double **Real1, double **Imag1, double **Real2, double **Imag2, int width, int height);
void fft(COMPLEX *x, int m);
void ifft(COMPLEX *x, int m);
```

<br>

## Filtering에 의한 영상복원

### moonN.256 영상의 FFT를 계산하고 화면에 Display 한다.

```cpp
void CHomework::OnClickedFft()
{
	// 선택한 영상의 가로, 세로, 위치좌표를 저장할 변수
	int width, height, x0, y0;
	// BYTE타입의 값을 저장하는 2차원 배열로 영상정보 저장
	BYTE **img;
	// 영상정보의 Real파트와 Imag파트 정보를 저장
	double **img_Real, **img_Imag;
	// 영상을 FFT한 결과 Real파트와 Imag파트 정보를 저장
	double **fft_Real, **fft_Imag;
	// 영상을 FFT하여 얻은 Real, Imag파트로 얻어낸 스펙트럼 정보를 저장
	double **Spectrum;
	// FFT 소요시간을 clock을 이용해 계산하기 위한 변수
	clock_t start_time, end_time;

	// 영상 정보 읽기
	if(!GetCurrentImageInfo(&width, &height, &x0, &y0)) return;

	img = cmatrix(height, width);
	img_Real = dmatrix(height, width);
	img_Imag = dmatrix(height, width);
	fft_Real = dmatrix(height, width);
	fft_Imag = dmatrix(height, width);
	Spectrum = dmatrix(height, width);

	// 회색조 영상 읽기
	GetCurrentImageGray(img);

	// 1) 이미지를 Real파트와 Imag파트로 분리
	// 2) 분리된 결과를 이용해 FFT
	// + 시작 측정을 위해 FFT 전/후로 clock정보를 받음
	Image_to_RealandImag(img, img_Real, img_Imag, width, height);
	start_time = clock();
	FFT_2D(img_Real, img_Imag, fft_Real, fft_Imag, width, height);
	end_time = clock();

	// 1) 계산된 Real파트와 Imag파트를 이용해 스펙트럼 계산
	// 2) 계산된 스펙트럼 값을 영상정보로 바꾸기위해 정규화
	// 3) 화면에 출력
	Compute_Spectrum(fft_Real, fft_Imag, width, height, Spectrum);
	DNormalize2D(Spectrum, img, width, height);
	DisplayCimage2D(img, width, height, x0+width, y0, true);
	
	// 1) 정규화된 영상을 중앙 변환
	// 2) 화면에 출력
	TranslationCenter(img, width, height);
	DisplayCimage2D(img, width, height, x0+width*2, y0, true);

	// 1) 계산된 Real파트와 Imag파트를 log를 이용해 스펙트럼 계산
	// 2) 계산된 스펙트럼 값을 영상정보로 바꾸기위해 정규화
	// 3) 화면에 출력
	Compute_Spectrum_log(fft_Real, fft_Imag, width, height, Spectrum);
	DNormalize2D(Spectrum, img, width, height);
	DisplayCimage2D(img, width, height, x0+width, y0+height, true);

	// 1) 정규화된 영상을 중앙 변환
	// 2) 화면에 출력
	TranslationCenter(img, width, height);
	DisplayCimage2D(img, width, height, x0+width*2, y0+height, true);

	// 1) 계산된 Real파트와 Imag파트를 다시 IFFT 계산
	// 2) 계산된 스펙트럼 값을 영상정보로 바꾸기위해 정규화
	// 3) 화면에 출력
	IFFT_2D(fft_Real, fft_Imag, img_Real, img_Imag, width, height);
	DNormalize2D(img_Real, img, width, height);
	DisplayCimage2D(img, width, height, x0, y0+height, true);

	// 화면에 FFT를 계산하는데 소요된 시간을 표현
	DisplayProcessingTime(start_time, end_time);

	free_cmatrix(img, height, width);
	free_dmatrix(img_Real, height, width);
	free_dmatrix(img_Imag, height, width);
	free_dmatrix(fft_Real, height, width);
	free_dmatrix(fft_Imag, height, width);
	free_dmatrix(Spectrum, height, width);
}
```

<br>

### FFT 영역 $F(u, v)$의 중심에서 같은 거리에 여러 개의 작은 점(Sinusoidal noise)을 확인하고 제거한다. Band Reject Filter를 통과된 FFT 계수만을 통과시키고 Inverse FFT에 의하여 복원된 영상 $\hat{f}(x, y)$을 계산하고 gray-level을 정규화하여 화면에 Display한다.

```cpp
void CHomework::OnClickedFilter1()
{
	// 선택한 영상의 가로, 세로, 위치좌표를 저장할 변수
	int width, height, x0, y0;
	// BYTE타입의 값을 저장하는 2차원 배열로 영상정보 저장
	BYTE **img;
	// 영상정보의 Real파트와 Imag파트 정보를 저장
	double **img_Real, **img_Imag;
	// 영상을 FFT한 결과 Real파트와 Imag파트 정보를 저장
	double **fft_Real, **fft_Imag;
	// 영상을 FFT하여 얻은 Real, Imag파트로 얻어낸 스펙트럼 정보를 저장
	double **Spectrum;
	// 필터를 통과하여 얻어낸 Real, Imag파트 정보를 저장
	double **recovered_Real, **recovered_Imag;

	// 영상 정보 읽기
	if (!GetCurrentImageInfo(&width, &height, &x0, &y0)) return;

	img = cmatrix(height, width);
	img_Real = dmatrix(height, width);
	img_Imag = dmatrix(height, width);
	fft_Real = dmatrix(height, width);
	fft_Imag = dmatrix(height, width);
	Spectrum = dmatrix(height, width);
	recovered_Real = dmatrix(height, width);
	recovered_Imag = dmatrix(height, width);

	// 회색조 영상 읽기
	GetCurrentImageGray(img);

	// 1) 이미지를 Real파트와 Imag파트로 분리
	// 2) 분리된 결과를 이용해 FFT
	Image_to_RealandImag(img, img_Real, img_Imag, width, height);
	FFT_2D(img_Real, img_Imag, fft_Real, fft_Imag, width, height);

	// 1) 계산된 Real파트와 Imag파트를 log를 이용해 스펙트럼 계산
	// 2) 계산된 스펙트럼 값을 영상정보로 바꾸기위해 정규화
	// 3) 정규화된 영상을 중앙 변환
	// 4) 화면에 출력
	Compute_Spectrum_log(fft_Real, fft_Imag, width, height, Spectrum);
	DNormalize2D(Spectrum, img, width, height);
	TranslationCenter(img, width, height);
	DisplayCimage2D(img, width, height, x0 + width, y0, true);

	// 1) Band Reject Filter를 통해 데이터 변경
	// 2) 변경된 Real파트와 Imag파트를 log를 이용해 스펙트럼 계산
	// 3) 계산된 스펙트럼 값을 영상정보로 바꾸기위해 정규화
	// 4) 정규화된 영상을 중앙 변환
	// 5) 화면에 출력
	BandRejectFilter(fft_Real, fft_Imag, width, height, 100, 4);
	Compute_Spectrum_log(fft_Real, fft_Imag, width, height, Spectrum);
	DNormalize2D(Spectrum, img, width, height);
	TranslationCenter(img, width, height);
	DisplayCimage2D(img, width, height, x0 + width, y0 + height, true);

	// 1) 필터를 통과하여 변경된 Real파트와 Imag파트를 다시 IFFT 계산
	// 2) 계산된 스펙트럼 값을 영상정보로 바꾸기위해 정규화
	// 3) 화면에 출력
	IFFT_2D(fft_Real, fft_Imag, recovered_Real, recovered_Imag, width, height);
	DNormalize2D(recovered_Real, img, width, height);
	DisplayCimage2D(img, width, height, x0, y0 + height, true);

	free_cmatrix(img, height, width);
	free_dmatrix(img_Real, height, width);
	free_dmatrix(img_Imag, height, width);
	free_dmatrix(fft_Real, height, width);
	free_dmatrix(fft_Imag, height, width);
	free_dmatrix(Spectrum, height, width);
	free_dmatrix(recovered_Real, height, width);
	free_dmatrix(recovered_Imag, height, width);
}
```

<br>

### 복원된 영상의 FFT를 계산하고 화면에 Display한다.

```cpp
void CHomework::OnClickedFft()
{
	// 선택한 영상의 가로, 세로, 위치좌표를 저장할 변수
	int width, height, x0, y0;
	// BYTE타입의 값을 저장하는 2차원 배열로 영상정보 저장
	BYTE **img;
	// 영상정보의 Real파트와 Imag파트 정보를 저장
	double **img_Real, **img_Imag;
	// 영상을 FFT한 결과 Real파트와 Imag파트 정보를 저장
	double **fft_Real, **fft_Imag;
	// 영상을 FFT하여 얻은 Real, Imag파트로 얻어낸 스펙트럼 정보를 저장
	double **Spectrum;
	// FFT 소요시간을 clock을 이용해 계산하기 위한 변수
	clock_t start_time, end_time;

	// 영상 정보 읽기
	if(!GetCurrentImageInfo(&width, &height, &x0, &y0)) return;

	img = cmatrix(height, width);
	img_Real = dmatrix(height, width);
	img_Imag = dmatrix(height, width);
	fft_Real = dmatrix(height, width);
	fft_Imag = dmatrix(height, width);
	Spectrum = dmatrix(height, width);

	// 회색조 영상 읽기
	GetCurrentImageGray(img);

	// 1) 이미지를 Real파트와 Imag파트로 분리
	// 2) 분리된 결과를 이용해 FFT
	// + 시작 측정을 위해 FFT 전/후로 clock정보를 받음
	Image_to_RealandImag(img, img_Real, img_Imag, width, height);
	start_time = clock();
	FFT_2D(img_Real, img_Imag, fft_Real, fft_Imag, width, height);
	end_time = clock();

	// 1) 계산된 Real파트와 Imag파트를 이용해 스펙트럼 계산
	// 2) 계산된 스펙트럼 값을 영상정보로 바꾸기위해 정규화
	// 3) 화면에 출력
	Compute_Spectrum(fft_Real, fft_Imag, width, height, Spectrum);
	DNormalize2D(Spectrum, img, width, height);
	DisplayCimage2D(img, width, height, x0+width, y0, true);
	
	// 1) 정규화된 영상을 중앙 변환
	// 2) 화면에 출력
	TranslationCenter(img, width, height);
	DisplayCimage2D(img, width, height, x0+width*2, y0, true);

	// 1) 계산된 Real파트와 Imag파트를 log를 이용해 스펙트럼 계산
	// 2) 계산된 스펙트럼 값을 영상정보로 바꾸기위해 정규화
	// 3) 화면에 출력
	Compute_Spectrum_log(fft_Real, fft_Imag, width, height, Spectrum);
	DNormalize2D(Spectrum, img, width, height);
	DisplayCimage2D(img, width, height, x0+width, y0+height, true);

	// 1) 정규화된 영상을 중앙 변환
	// 2) 화면에 출력
	TranslationCenter(img, width, height);
	DisplayCimage2D(img, width, height, x0+width*2, y0+height, true);

	// 1) 계산된 Real파트와 Imag파트를 다시 IFFT 계산
	// 2) 계산된 스펙트럼 값을 영상정보로 바꾸기위해 정규화
	// 3) 화면에 출력
	IFFT_2D(fft_Real, fft_Imag, img_Real, img_Imag, width, height);
	DNormalize2D(img_Real, img, width, height);
	DisplayCimage2D(img, width, height, x0, y0+height, true);

	// 화면에 FFT를 계산하는데 소요된 시간을 표현
	DisplayProcessingTime(start_time, end_time);

	free_cmatrix(img, height, width);
	free_dmatrix(img_Real, height, width);
	free_dmatrix(img_Imag, height, width);
	free_dmatrix(fft_Real, height, width);
	free_dmatrix(fft_Imag, height, width);
	free_dmatrix(Spectrum, height, width);
}
```

<br>

### HouseN.256 영상에 대해 영상복원 과정을 수행한다.

```cpp
void CHomework::OnClickedFilter2()
{
	// 선택한 영상의 가로, 세로, 위치좌표를 저장할 변수
	int width, height, x0, y0;
	// BYTE타입의 값을 저장하는 2차원 배열로 영상정보 저장
	BYTE **img;
	// 영상정보의 Real파트와 Imag파트 정보를 저장
	double **img_Real, **img_Imag;
	// 영상을 FFT한 결과 Real파트와 Imag파트 정보를 저장
	double **fft_Real, **fft_Imag;
	// 영상을 FFT하여 얻은 Real, Imag파트로 얻어낸 스펙트럼 정보를 저장
	double **Spectrum;
	// 필터를 통과하여 얻어낸 Real, Imag파트 정보를 저장
	double **recovered_Real, **recovered_Imag;

	// 영상 정보 읽기
	if (!GetCurrentImageInfo(&width, &height, &x0, &y0)) return;

	img = cmatrix(height, width);
	img_Real = dmatrix(height, width);
	img_Imag = dmatrix(height, width);
	fft_Real = dmatrix(height, width);
	fft_Imag = dmatrix(height, width);
	Spectrum = dmatrix(height, width);
	recovered_Real = dmatrix(height, width);
	recovered_Imag = dmatrix(height, width);

	// 회색조 영상 읽기
	GetCurrentImageGray(img);

	// 1) 이미지를 Real파트와 Imag파트로 분리
	// 2) 분리된 결과를 이용해 FFT
	Image_to_RealandImag(img, img_Real, img_Imag, width, height);
	FFT_2D(img_Real, img_Imag, fft_Real, fft_Imag, width, height);

	// 1) 계산된 Real파트와 Imag파트를 log를 이용해 스펙트럼 계산
	// 2) 계산된 스펙트럼 값을 영상정보로 바꾸기위해 정규화
	// 3) 정규화된 영상을 중앙 변환
	// 4) 화면에 출력
	Compute_Spectrum_log(fft_Real, fft_Imag, width, height, Spectrum);
	DNormalize2D(Spectrum, img, width, height);
	TranslationCenter(img, width, height);
	DisplayCimage2D(img, width, height, x0 + width, y0, true);

	// 1) Filter2를 통해 데이터 변경
	// 2) 변경된 Real파트와 Imag파트를 log를 이용해 스펙트럼 계산
	// 3) 계산된 스펙트럼 값을 영상정보로 바꾸기위해 정규화
	// 4) 정규화된 영상을 중앙 변환
	// 5) 화면에 출력
	Filter2(fft_Real, fft_Imag, 55, 25);
	Filter2(fft_Real, fft_Imag, 215, 12);
	Filter2(fft_Real, fft_Imag, 37, 241);
	Filter2(fft_Real, fft_Imag, 198, 231);
	Compute_Spectrum_log(fft_Real, fft_Imag, width, height, Spectrum);
	DNormalize2D(Spectrum, img, width, height);
	TranslationCenter(img, width, height);
	DisplayCimage2D(img, width, height, x0 + width, y0 + height, true);

	// 1) 필터를 통과하여 변경된 Real파트와 Imag파트를 다시 IFFT 계산
	// 2) 계산된 스펙트럼 값을 영상정보로 바꾸기위해 정규화
	// 3) 화면에 출력
	IFFT_2D(fft_Real, fft_Imag, recovered_Real, recovered_Imag, width, height);
	DNormalize2D(recovered_Real, img, width, height);
	DisplayCimage2D(img, width, height, x0, y0 + height, true);

	free_cmatrix(img, height, width);
	free_dmatrix(img_Real, height, width);
	free_dmatrix(img_Imag, height, width);
	free_dmatrix(fft_Real, height, width);
	free_dmatrix(fft_Imag, height, width);
	free_dmatrix(Spectrum, height, width);
	free_dmatrix(recovered_Real, height, width);
	free_dmatrix(recovered_Imag, height, width);
}
```

<br>

## Mean-filtering과 Median-filtering

### Mean-filtering에 의한 영상복원 (3x3 window 사용)

```cpp
void CHomework::OnClickedMeanFilter()
{
	// 선택한 영상의 가로, 세로, 위치좌표를 저장할 변수
	int width, height, x0, y0;
	// BYTE타입의 값을 저장하는 2차원 배열로 영상정보 저장
	BYTE **img;

	// 영상 정보 읽기
	if (!GetCurrentImageInfo(&width, &height, &x0, &y0)) return;

	img = cmatrix(height, width);

	// 회색조 영상 읽기
	GetCurrentImageGray(img);

	// Mean-filtering후 화면에 출력
	MeanFilter(img, width, height, 3);
	DisplayCimage2D(img, width, height, x0 + width, y0, true);

	free_cmatrix(img, height, width);
}
```

<br>

### Median-filtering에 의한 영상복원 (3x3 window 사용)

```cpp
void CHomework::OnClickedMedianFilter()
{
	// 선택한 영상의 가로, 세로, 위치좌표를 저장할 변수
	int width, height, x0, y0;
	// BYTE타입의 값을 저장하는 2차원 배열로 영상정보 저장
	BYTE **img;

	// 영상 정보 읽기
	if (!GetCurrentImageInfo(&width, &height, &x0, &y0)) return;

	img = cmatrix(height, width);

	// 회색조 영상 읽기
	GetCurrentImageGray(img);

	// Median-filtering후 화면에 출력
	MedianFilter(img, width, height, 3);
	DisplayCimage2D(img, width, height, x0 + width*2, y0, true);

	free_cmatrix(img, height, width);
}
```

<br>

## 결과

### moonN.256 영상의 FFT
![1-1](https://user-images.githubusercontent.com/79047370/114693435-8ccd2380-9d54-11eb-8b1e-7af7be067ca2.png)
첫번째 사진을 보면 달 사진에 대하여 노이즈가 껴있는 것을 확인할 수 있다. 따라서 FFT를 한 후 Display해보았다.<br>
가장 오른쪽 아래사진을 보면 영상의 중심을 기준으로 비슷한 거리에 8개의 밝은 점이 보인다. 해당 주파수 대역에 대하여 이와 같이 높은 값을 가질 데이터가 존재하는 것이 이상하다. 8개의 점이 노이즈라 판단하였고, 이 점들이 중심으로부터 비슷한 거리에 있기때문에 비슷한 대역의 값들을 제거해주기로 결정했다.

### Band-Reject Filtering를 통해 노이즈 제거 후 영상복원
![1-2](https://user-images.githubusercontent.com/79047370/114693451-8e96e700-9d54-11eb-8fac-0e6a7a2d5096.png)
원영상에 대해 FFT 결과와 위에서 구현한 필터를 취하여 얻어낸 FFT 결과를 함께 나타내보았다. 또한, 필터를 취해 얻은 결과를 다시 IFFT를 통해 영상을 복원해보았다.<br>
오른쪽 아래 사진을 보면 영상의 중심을 기준으로 노이즈가 분포하던 부분에 원 형태로 값들을 모두 제거하여 검은 모습으로 나타나는 것을 확인할 수 있다. 또한, 이 스펙트럼을 다시 IFFT하였더니 왼쪽 아래 사진처럼 노이즈가 제거되고 선명한 사진을 얻은 것을 확인할 수 있다.

### 복원된 moonN.256 영상의 FFT
![1-3](https://user-images.githubusercontent.com/79047370/114693453-8f2f7d80-9d54-11eb-8cdf-e33d7fb0f51a.png)
위 문제를 통해 복원된 영상을 다시한번 FFT를 한 후 Display해보았다.<br>
위와 큰 차이없이 동일한 결과가 나오는 것을 알 수 있다.

### HouseN.256 영상의 FFT & 부분적 노이즈 필터링 후 영상복원
![1-4-1](https://user-images.githubusercontent.com/79047370/114693454-8fc81400-9d54-11eb-9e48-4e9a907423dd.png)
첫번째 사진을 보면 어떤 영상인지 확인할 수 없을 정도의 사진 처음으로 나타나 있고, 이를 분석하기 위해 FFT를 한 후 Display해본 결과이다.<br>
가장 오른쪽 아래 사진을 보면 중심을 기준으로 4개의 밝은 점이 대칭적으로 분포해있다. 마찬가지로 밝은 4개의 점이 노이즈라 판단하여 제거하기 위해 필터를 구성했다.

![1-4-2](https://user-images.githubusercontent.com/79047370/114693459-90f94100-9d54-11eb-8d5d-4ac1912b9858.png)
구성한 필터를 HouseN.256 영상에 실행해주었다.<br>
오른쪽 아래 사진을 보면 스펙트럼에서 밝게 나타나던 4개의 점 근처의 값들을 모두 0으로 만들어 노이즈를 제거해주었다. 노이즈가 제거된 스펙트럼을 다시 IFFT 한 후 복원된 영상을 Display했더니 House 영상이 선명하게 나타나는 것을 확인할 수 있다.

### ApeN2.256 영상의 Mean-filtering
![2-1](https://user-images.githubusercontent.com/79047370/114693462-9191d780-9d54-11eb-8e7c-5f089f8eccfd.png)
사진의 왼쪽 영상이 ApeN.256이다. 굉장히 노이즈가 많은 것을 확인할 수 있다. 이 영상을 FFT하더라도 노이즈 값을 확인할 수 없어 Mean-filter를 이용해보았다.<br>
Mean_filter란 특정 점에 대하여 주변 점(해당 문제에서는 3x3 window)에 대하여 값들의 평균값으로 값을 바꿔주는 필터이다. 원영상에 검은 점들이 굉장히 많기 때문에 이것들을 제거하기 위해 사용해주었다. 사용한 후 거의 모든 노이즈들이 제거된 것을 확인할 수 있다. 노이즈가 많이 제거되었지만 완벽하게 선명한 영상으로는 만들지 못한 것이 아쉽다.


### ApeN2.256 영상의 Median-filtering
![2-2](https://user-images.githubusercontent.com/79047370/114693464-9191d780-9d54-11eb-8522-2506b86afd81.png)
사진의 왼쪽 영상이 ApeN.256이다. 마찬가지로 노이즈가 많고 FFT를 통해 노이즈 값을 확인할 수 없어 Median-filter를 이용해보았다.<br>
Median-filter란 특정 점에 대하여 주변 점(해당 문제에서는 3x3 window)에 대하여 값들의 중간값으로 값을 바꿔주는 필터이다. 원영상에 많이 분포되어있는 검은 점들을 제거하기 위해 사용해주었다. 사용한 후 노이즈들이 굉장히 많이 제거된 것을 확인할 수 있다. Mean-filter와 비교했을 때 조금 더 선명해보이는 영상을 얻을 수 있었지만, 몇몇 노이즈들이 조금은 남아있는 것을 확인할 수 있었다.

<br>

## Functions.

```cpp
// 스펙트럼 계산
void Compute_Spectrum(double **Real, double **Imag, int width, int height, double **Spectrum)
{
	for (int v = 0; v < height; v++)
		for (int u = 0; u < width; u++)
			Spectrum[v][u] = sqrt(Real[v][u]*Real[v][u] + Imag[v][u]*Imag[v][u]);
}
```

```cpp
// 로그를 이용해 스펙트럼 계산
void Compute_Spectrum_log(double **Real, double **Imag, int width, int height, double **Spectrum)
{
	for (int v = 0; v < height; v++)
		for (int u = 0; u < width; u++)
			Spectrum[v][u] = log(1. + sqrt(Real[v][u]*Real[v][u] + Imag[v][u]*Imag[v][u]));
}
```

```cpp
// 스펙트럼 정규화
void DNormalize2D(double **Spt, BYTE **img, int width, int height)
{
	// 스펙트럼의 최대값, 최소값, 현재값을 저장할 변수
	double min = 9999.;
	double max = -9999.;
	double val;

	// 스펙트럼의 최대값과 최소값을 파악
	for (int y = 0; y < height; y++)
	{
		for (int x = 0; x < width; x++)
		{
			val = Spt[y][x];
			if (val > max) max = val;
			if (val < min) min = val;
		}
	}

	// 스펙트럼이 없는 경우
	if (max == min)
	{
		for (int y = 0; y < height; y++)
			for (int x = 0; x < width; x++)
				img[y][x] = 0;
		return;
	}

	// 스펙트럼 값을 gray-level로 정규화
	double dfactor = 255 / (max-min);
	for (int y = 0; y < height; y++)
		for (int x = 0; x < width; x++)
			img[y][x] = (BYTE)((Spt[y][x] - min) * dfactor);
}
```

```cpp
// 영상 중심 이동
void TranslationCenter(BYTE **image, int width, int height)
{
	// 원영상 정보를 저장할 2차원 배열
	BYTE **temp_img;
	temp_img = cmatrix(height, width);
	for (int y = 0; y < height; y++)
		for (int x = 0; x < width; x++)
			temp_img[y][x] = image[y][x];
	

	int xp, yp;
	for (int y = 0; y < height; y++)
	{
		for (int x = 0; x < width; x++)
		{
			// 왼쪽 상단 영상정보를 오른쪽 하단 영상정보로 교체
			if (x >= 0 && x < (int)width/2 && y >= 0 && y < (int)height/2)
			{
				xp = x + (int)width/2;
				yp = y + (int)height/2;
				image[y][x] = temp_img[yp][xp];
			}
			// 오른쪽 상단 영상정보를 왼쪽 하단 영상정보로 교체
			else if (x >= (int)width/2 && x < width && y >= 0 && y < (int)height/2)
			{
				xp = x - (int)width/2;
				yp = y + (int)height/2;
				image[y][x] = temp_img[yp][xp];
			}
			// 왼쪽 하단 영상정보를 오른쪽 상단 영상정보로 교체
			else if (x >= 0 && x < (int)width/2 && y >= (int)height/2 && y < height)
			{
				xp = x + (int)width/2;
				yp = y - (int)height/2;
				image[y][x] = temp_img[yp][xp];
			}
			// 오른쪽 하단 영상정보를 왼쪽 상단 영상정보로 교체
			else
			{
				xp = x - (int)width/2;
				yp = y - (int)height/2;
				image[y][x] = temp_img[yp][xp];
			}
		}
	}
	free_cmatrix(temp_img, height, width);
}
```

```cpp
// 영상정보를 Real파트와 Imag파트로 분리
void Image_to_RealandImag(BYTE **image, double **Real, double **Imag, int width, int height)
{
	// 영상정보는 허수정보가 없기때문에 모두 실수정보에 저장
	for (int y = 0; y < height; y++)
	{
		for (int x = 0; x < width; x++)
		{
			Real[y][x] = (double)image[y][x];
			Imag[y][x] = 0.;
		}
	}
}
```

```cpp
// 처리시간을 화면에 출력
void DisplayProcessingTime(clock_t start_time, clock_t end_time)
{
	// 시간차를 저장할 변수
	double time_dif;

	// 클럭정보로부터 시간차를 계산해 처리시간을 화면에 출력
	time_dif = (double)((end_time - start_time)/(double)CLOCKS_PER_SEC);
	CString ViewMsg;
	ViewMsg.Format(_T("Processing time: %7.3f sec"), time_dif);
	SetViewMsg(ViewMsg);
}
```

```cpp
void BandRejectFilter(double **Real, double **Imag, int width, int height, int distance, int range)
{
	// 원점으로부터 떨어진 거리
	double D;

	for (int y = 0; y < height; y++)
	{
		for (int x = 0; x < width; x++)
		{
			// 왼쪽 상단 데이터
			if (x >= 0 && x < width / 2 && y >= 0 && y < height / 2)
			{
				D = sqrt((double)(x * x + y * y));
				if (distance - range <= D && D <= distance + range)
				{
					Real[y][x] = 0.;
					Imag[y][x] = 0.;
				}
			}
			// 오른쪽 상단 데이터
			else if (x >= width / 2 && x < width && y >= 0 && y < (height / 2))
			{
				D = sqrt((double)((width - x) * (width - x) + y * y));
				if (distance - range <= D && D <= distance + range)
				{
					Real[y][x] = 0.;
					Imag[y][x] = 0.;
				}
			}
			// 왼쪽 하단 데이터
			else if (x >= 0 && x < width / 2 && y >= height / 2 && y < height)
			{
				D = sqrt((double)(x * x + (height - y) * (height - y)));
				if (distance - range <= D && D <= distance + range)
				{
					Real[y][x] = 0.;
					Imag[y][x] = 0.;
				}
			}
			// 오른쪽 하단 데이터
			else
			{
				D = sqrt((double)((width - x) * (width - x) + (height - y) * (height - y)));
				if (distance - range <= D && D <= distance + range)
				{
					Real[y][x] = 0.;
					Imag[y][x] = 0.;
				}
			}
		}
	}
}
```

```cpp
void Filter2(double **Real, double **Imag, int noise_x, int noise_y)
{
	// noise 좌표를 기준으로 +/- 5범위의 값들을 0으로 변경
	for (int y = noise_y -  5; y <= noise_y + 5; y++)
	{
		for (int x = noise_x - 5; x <= noise_x + 5; x++)
		{
			Real[y][x] = 0.;
			Imag[y][x] = 0.;
		}
	}
}
```

```cpp
void MeanFilter(BYTE **image, int width, int height, int window_size)
{
	// 현재 영상정보를 저장할 2차원 배열
	BYTE **temp_img;
	temp_img = cmatrix(height, width);

	// 윈도우 크기의 절반
	int half_ws = (window_size - 1) / 2;

	// 원영상을 temp_img에 복사
	for (int y = 0; y < height; y++)
		for (int x = 0; x < width; x++)
			temp_img[y][x] = image[y][x];

	// 원영상을 3x3 윈도우의 평균값으로 수정
	for (int y = half_ws; y < height - half_ws; y++)
	{
		for (int x = half_ws; x < width - half_ws; x++)
		{
			// average에 3x3 윈도우 값들의 평균을 저장 후 원영상 수정
			BYTE average = 0;
			for (int j = -1 * half_ws; j <= half_ws; j++)
				for (int i = -1 * half_ws; i <= half_ws; i++)
					average += temp_img[y + j][x + i] / (window_size * window_size);
			image[y][x] = average;
		}
	}
	free_cmatrix(temp_img, height, width);
}
```

```cpp
void MedianFilter(BYTE **image, int width, int height, int window_size)
{
	// 현재 영상정보를 저장할 2차원 배열
	BYTE **temp_img;
	temp_img = cmatrix(height, width);

	// 윈도우 크기의 절반
	int half_ws = (window_size - 1) / 2;

	// 원영상을 temp_img에 복사
	for (int y = 0; y < height; y++)
		for (int x = 0; x < width; x++)
			temp_img[y][x] = image[y][x];

	// 원영상을 3x3 윈도우의 중간값으로 수정
	for (int y = half_ws; y < height - half_ws; y++)
	{
		for (int x = half_ws; x < width - half_ws; x++)
		{
			// 1차원 배열에 3x3 윈도우 값들을 저장
			BYTE values[9] = { 0, 0, 0, 0, 0, 0, 0, 0, 0 };
			for (int j = -1 * half_ws; j <= half_ws; j++)
				for (int i = -1 * half_ws; i <= half_ws; i++)
					values[window_size * half_ws + half_ws + j * window_size + i * half_ws] = temp_img[y + j][x + i];
			// 선택 정렬 방식을 이용해 중간값을 찾아 원영상을 수정
			selectionsort(values, window_size * window_size);
			image[y][x] = values[window_size * half_ws + half_ws];
		}
	}
	free_cmatrix(temp_img, height, width);
}
```

```cpp
void selectionsort(BYTE *values, int length)
{
	int min_index;
	BYTE temp;
	for (int i = 0; i < length; i++)
	{
		min_index = i;
		for (int j = i + 1; j < length; j++)
			if (values[j] < values[min_index])
				min_index = j;
		temp = values[i];
		values[i] = values[min_index];
		values[min_index] = temp;
	}
}
```

```cpp
// 2-D FFT 계산
void FFT_2D(double **Real1, double **Imag1, double **Real2, double **Imag2, int width, int height)
{
	// 반복문 수행에 사용될 x, y 변수
	int x, y;
	// 영상크기 Byte값을 저장할 변수
	int LN = (int)(log((double)width) / log(2.));
	// 1차원 FFT 결과를 저장할 임시 배열
	COMPLEX *temp = (COMPLEX*)malloc(sizeof(COMPLEX) * width);

	// Row-FFT Transform
	for (y = 0; y < height; y++)
	{
		for (x = 0; x < width; x++)
		{
			temp[x].real = Real1[y][x];
			temp[x].imag = Imag1[y][x];
		}

		fft(temp, LN);

		for (x = 0; x < width; x++)
		{
			Real2[y][x] = temp[x].real;
			Imag2[y][x] = temp[x].imag;
		}
	}

	// Column-FFT Transform
	for (x = 0; x < width; x++)
	{
		for (y = 0; y < height; y++)
		{
			temp[y].real = Real2[y][x];
			temp[y].imag = Imag2[y][x];
		}
		fft(temp, LN);
		for (y = 0; y < height; y++)
		{
			Real2[y][x] = temp[y].real;
			Imag2[y][x] = temp[y].imag;
		}
	}

	free(temp);
}
```

```cpp
// 2-D IFFT 계산
void IFFT_2D(double **Real1, double **Imag1, double **Real2, double **Imag2, int width, int height)
{
	// 반복문 수행에 사용될 x, y 변수
	int x, y;
	// 영상크기 Byte값을 저장할 변수
	int LN = (int)(log((double)width) / log(2.));
	// 1차원 FFT 결과를 저장할 임시 배열
	COMPLEX * temp = (COMPLEX*)malloc(sizeof(COMPLEX) * width);

	// Row-IFFT Transform
	for (y = 0; y < height; y++)
	{
		for (x = 0; x < width; x++)
		{
			temp[x].real = Real1[y][x];
			temp[x].imag = Imag1[y][x];
		}

		ifft(temp, LN);

		for (x = 0; x < width; x++)
		{
			Real2[y][x] = temp[x].real;
			Imag2[y][x] = temp[x].imag;
		}
	}

	// Column-IFFT Transform
	for (x = 0; x < width; x++)
	{
		for (y = 0; y < height; y++)
		{
			temp[y].real = Real2[y][x];
			temp[y].imag = Imag2[y][x];
		}
		ifft(temp, LN);
		for (y = 0; y < height; y++)
		{
			Real2[y][x] = temp[y].real;
			Imag2[y][x] = temp[y].imag;
		}
	}

	free(temp);
}
```

```cpp
// 2-D FFT 계산
void fft(COMPLEX *x, int m)
{
    static COMPLEX *w;      /* used to store the w COMPLEX array */
    static int mstore = 0;  /* stores m for future reference */
    static int n = 1;       /* length of fft stored for future */

    COMPLEX u, temp, tm;
    COMPLEX *xi, *xip, *xj, *wptr;

    long i, j, k, l, le, windex;

    double arg, w_real, w_imag, wrecur_real, wrecur_imag, wtemp_real;

    if(m != mstore)
    {
        /* free previously allocated storage and set new m */
        if(mstore != 0) free(w);
        mstore = m;
        if(m == 0) return;  /* if m=0 then done */

        /* n = 2**m = fft length */

        n = 1 << m;
        le = n/2;

        /* allocate the storage for w */

        w = (COMPLEX  *)malloc((long)(le-1) * (long)sizeof(COMPLEX));

        /* calculate the w values recursively */

        arg = 4.0*atan(1.0)/le;     /* PI/le calculation */
        wrecur_real = w_real = cos(arg);
        wrecur_imag = w_imag = -sin(arg);
	    for (j = 1 ; j < le ; j++)
        {
            (w + j - 1)->real = (float)wrecur_real;
            (w + j - 1)->imag = (float)wrecur_imag;
            wtemp_real = wrecur_real*w_real - wrecur_imag*w_imag;
            wrecur_imag = wrecur_real*w_imag + wrecur_imag*w_real;
            wrecur_real = wtemp_real;
        }
    }

    /* start fft */

    le = n;
    windex = 1;
    for (l = 0 ; l < m ; l++)
    {
        le = le/2;

        /* first iteration with no multiplies */

        for(i = 0 ; i < n ; i = i + 2*le)
        {
            xi = x + i;
            xip = xi + le;
            temp.real = xi->real + xip->real;
            temp.imag = xi->imag + xip->imag;
            xip->real = xi->real - xip->real;
            xip->imag = xi->imag - xip->imag;
            *xi = temp;
        }

        /* remaining iterations use stored w */

        wptr = w + windex - 1;
        for (j = 1 ; j < le ; j++)
        {
            u = *wptr;
            for (i = j ; i < n ; i = i + 2*le)
            {
                xi = x + i;
                xip = xi + le;
                temp.real = xi->real + xip->real;
                temp.imag = xi->imag + xip->imag;
                tm.real = xi->real - xip->real;
                tm.imag = xi->imag - xip->imag;
                xip->real = tm.real*u.real - tm.imag*u.imag;
                xip->imag = tm.real*u.imag + tm.imag*u.real;
                *xi = temp;
            }
            wptr = wptr + windex;
        }
        windex = 2*windex;
    }            

    /* rearrange data by bit reversing */

    j = 0;
    for (i = 1 ; i < (n-1) ; i++)
    {
        k = n/2;
        while(k <= j)
        {
            j = j - k;
            k = k/2;
        }
        j = j + k;
        if (i < j)
        {
            xi = x + i;
            xj = x + j;
            temp = *xj;
            *xj = *xi;
            *xi = temp;
        }
    }
}
```

```cpp
// 2-D IFFT 계산
void ifft(COMPLEX *x, int m)
{
    static COMPLEX *w;      /* used to store the w COMPLEX array */
    static int mstore = 0;  /* stores m for future reference */
    static int n = 1;       /* length of fft stored for future */

    COMPLEX u, temp, tm;
    COMPLEX *xi, *xip, *xj, *wptr;

    long i, j, k, l, le, windex;

    double arg,w_real, w_imag, wrecur_real, wrecur_imag, wtemp_real;
    float scale;

    if(m != mstore)
    {
        /* free previously allocated storage and set new m */

        if(mstore != 0) free(w);
        mstore = m;
        if(m == 0) return;      /* if m=0 then done */

        /* n = 2**m = inverse fft length */

        n = 1 << m;
        le = n/2;

        /* allocate the storage for w */

        w = (COMPLEX  *)malloc( (long)(le-1) * (long)sizeof(COMPLEX));

        /* calculate the w values recursively */

        arg = 4.0*atan(1.0)/le;     /* PI/le calculation */
        wrecur_real = w_real = cos(arg);
        wrecur_imag = w_imag = sin(arg); 

	    for (j = 1 ; j < le ; j++)
        {
            (w + j - 1)->real = (float)wrecur_real;
            (w + j - 1)->imag = (float)wrecur_imag;
            wtemp_real = wrecur_real*w_real - wrecur_imag*w_imag;
            wrecur_imag = wrecur_real*w_imag + wrecur_imag*w_real;
            wrecur_real = wtemp_real;
        }
    }

    /* start inverse fft */

    le = n;
    windex = 1;
    for (l = 0 ; l < m ; l++)
    {
        le = le/2;

        /* first iteration with no multiplies */

        for(i = 0 ; i < n ; i = i + 2*le)
        {
            xi = x + i;
            xip = xi + le;
            temp.real = xi->real + xip->real;
            temp.imag = xi->imag + xip->imag;
            xip->real = xi->real - xip->real;
            xip->imag = xi->imag - xip->imag;
            *xi = temp;
        }

        /* remaining iterations use stored w */

        wptr = w + windex - 1;
        for (j = 1 ; j < le ; j++)
        {
            u = *wptr;
            for (i = j ; i < n ; i = i + 2*le)
            {
                xi = x + i;
                xip = xi + le;
                temp.real = xi->real + xip->real;
                temp.imag = xi->imag + xip->imag;
                tm.real = xi->real - xip->real;
                tm.imag = xi->imag - xip->imag;
                xip->real = tm.real*u.real - tm.imag*u.imag;
                xip->imag = tm.real*u.imag + tm.imag*u.real;
                *xi = temp;
            }
            wptr = wptr + windex;
        }
        windex = 2*windex;
    }            

    /* rearrange data by bit reversing */

    j = 0;
    for (i = 1 ; i < (n-1) ; i++)
    {
        k = n/2;
        while(k <= j)
        {
            j = j - k;
            k = k/2;
        }
        j = j + k;
        if (i < j)
        {
            xi = x + i;
            xj = x + j;
            temp = *xj;
            *xj = *xi;
            *xi = temp;
        }
    }

    /* scale all results by 1/n */
    scale = (float)(1.0/n);
    for(i = 0 ; i < n ; i++)
    {
        x->real = scale*x->real;
        x->imag = scale*x->imag;
        x++;
    }
}
```